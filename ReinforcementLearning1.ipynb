{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMqxG/LPc3VN8j6sfo7xqjs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jdwittenauer/colab/blob/main/ReinforcementLearning1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7L2DOW5sM8Fc"
      },
      "outputs": [],
      "source": [
        "!sudo apt-get update\n",
        "!apt install python-opengl\n",
        "!apt install ffmpeg\n",
        "!apt install xvfb\n",
        "!apt install swig cmake\n",
        "!pip install setuptools==65.5.0\n",
        "!pip install stable-baselines3[extra]\n",
        "!pip install box2d-py\n",
        "!pip install huggingface_sb3\n",
        "!pip install pyglet==1.5.1\n",
        "!pip install shimmy>=0.2.1\n",
        "!pip3 install pyvirtualdisplay"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# os.kill(os.getpid(), 9)"
      ],
      "metadata": {
        "id": "d-X_x3n_9jBy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyvirtualdisplay import Display\n",
        "\n",
        "virtual_display = Display(visible=0, size=(1400, 900))\n",
        "virtual_display.start()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "af1fC-2hNi_v",
        "outputId": "7bf21776-f5dd-4a70-c5cf-ee70c6b5700a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyvirtualdisplay.display.Display at 0x7f75f5ac1fd0>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "from stable_baselines3.common.env_util import make_vec_env"
      ],
      "metadata": {
        "id": "us4oXRM7Ot4d"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env = gym.make(\"LunarLander-v2\")\n",
        "env.reset()\n",
        "print(\"_____OBSERVATION SPACE_____ \\n\")\n",
        "print(\"Observation Space Shape\", env.observation_space.shape)\n",
        "print(\"Sample observation\", env.observation_space.sample())  # Get a random observation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HslBb3L-ROdj",
        "outputId": "2387d92a-7dd3-4c32-9b65-c8debbcbd459"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "_____OBSERVATION SPACE_____ \n",
            "\n",
            "Observation Space Shape (8,)\n",
            "Sample observation [-0.64990604  0.55829227  0.5883102   0.27401125  0.14785583 -0.6835057\n",
            "  0.22491768 -0.7035305 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n _____ACTION SPACE_____ \\n\")\n",
        "print(\"Action Space Shape\", env.action_space.n)\n",
        "print(\"Action Space Sample\", env.action_space.sample())  # Take a random action"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WduXgEOk0bUL",
        "outputId": "9e4b5faf-979d-4931-f265-c26c423468b2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " _____ACTION SPACE_____ \n",
            "\n",
            "Action Space Shape 4\n",
            "Action Space Sample 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the environment\n",
        "env = make_vec_env(\"LunarLander-v2\", n_envs=16)"
      ],
      "metadata": {
        "id": "-OjTDaN21Obw"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the agent\n",
        "model = PPO(\n",
        "    policy=\"MlpPolicy\",\n",
        "    env=env,\n",
        "    n_steps=1024,\n",
        "    batch_size=64,\n",
        "    n_epochs=4,\n",
        "    gamma=0.999,\n",
        "    gae_lambda=0.98,\n",
        "    ent_coef=0.01,\n",
        "    verbose=1,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JhPVkdYN1lCZ",
        "outputId": "f94fa16b-90b6-4492-83fb-0d598e22d1d2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the agent\n",
        "model.learn(total_timesteps=100000)\n",
        "model_name = \"ppo-LunarLander-v2\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TD4TRoGn2MyX",
        "outputId": "8c8a010d-7f43-4ee2-ef62-76831b71209e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 93.1     |\n",
            "|    ep_rew_mean     | -192     |\n",
            "| time/              |          |\n",
            "|    fps             | 1769     |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 9        |\n",
            "|    total_timesteps | 16384    |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 98.4        |\n",
            "|    ep_rew_mean          | -139        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1771        |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 18          |\n",
            "|    total_timesteps      | 32768       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010972676 |\n",
            "|    clip_fraction        | 0.0505      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.38       |\n",
            "|    explained_variance   | 0.00171     |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.51e+03    |\n",
            "|    n_updates            | 4           |\n",
            "|    policy_gradient_loss | -0.00566    |\n",
            "|    value_loss           | 4.93e+03    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 91           |\n",
            "|    ep_rew_mean          | -124         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1694         |\n",
            "|    iterations           | 3            |\n",
            "|    time_elapsed         | 29           |\n",
            "|    total_timesteps      | 49152        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0057592513 |\n",
            "|    clip_fraction        | 0.0289       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.37        |\n",
            "|    explained_variance   | -0.00101     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 731          |\n",
            "|    n_updates            | 8            |\n",
            "|    policy_gradient_loss | -0.0032      |\n",
            "|    value_loss           | 2.21e+03     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 92.5        |\n",
            "|    ep_rew_mean          | -109        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1578        |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 41          |\n",
            "|    total_timesteps      | 65536       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008729126 |\n",
            "|    clip_fraction        | 0.0686      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.35       |\n",
            "|    explained_variance   | -0.00193    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 344         |\n",
            "|    n_updates            | 12          |\n",
            "|    policy_gradient_loss | -0.00661    |\n",
            "|    value_loss           | 1.11e+03    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 97.6         |\n",
            "|    ep_rew_mean          | -95.7        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1551         |\n",
            "|    iterations           | 5            |\n",
            "|    time_elapsed         | 52           |\n",
            "|    total_timesteps      | 81920        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0059869434 |\n",
            "|    clip_fraction        | 0.0561       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.34        |\n",
            "|    explained_variance   | 0.00124      |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 353          |\n",
            "|    n_updates            | 16           |\n",
            "|    policy_gradient_loss | -0.00402     |\n",
            "|    value_loss           | 657          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 99.1         |\n",
            "|    ep_rew_mean          | -77.4        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1568         |\n",
            "|    iterations           | 6            |\n",
            "|    time_elapsed         | 62           |\n",
            "|    total_timesteps      | 98304        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0076244213 |\n",
            "|    clip_fraction        | 0.0816       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.34        |\n",
            "|    explained_variance   | -0.0804      |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 346          |\n",
            "|    n_updates            | 20           |\n",
            "|    policy_gradient_loss | -0.0039      |\n",
            "|    value_loss           | 531          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 107          |\n",
            "|    ep_rew_mean          | -72.2        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1556         |\n",
            "|    iterations           | 7            |\n",
            "|    time_elapsed         | 73           |\n",
            "|    total_timesteps      | 114688       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0119696865 |\n",
            "|    clip_fraction        | 0.144        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.3         |\n",
            "|    explained_variance   | -0.068       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 181          |\n",
            "|    n_updates            | 24           |\n",
            "|    policy_gradient_loss | -0.00631     |\n",
            "|    value_loss           | 422          |\n",
            "------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_env = gym.make(\"LunarLander-v2\")\n",
        "mean_reward, std_reward = evaluate_policy(model, eval_env, n_eval_episodes=10, deterministic=True)\n",
        "print(f\"mean_reward={mean_reward:.2f} +/- {std_reward}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQHBe4tM2Zzf",
        "outputId": "419ce012-3da1-4b72-b82f-40a86afae2f4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean_reward=-115.53 +/- 97.03260578074\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IlSAFx_b7e19"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}